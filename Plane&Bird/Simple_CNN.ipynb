{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9194532507529919557\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6705216225\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7123710772436939135\n",
      "physical_device_desc: \"device: 0, name: Quadro P4000, pci bus id: 0000:65:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('input/train_x.csv', index_col=0, header=None)\n",
    "train_y = pd.read_csv('input/train_y.csv', index_col=0)\n",
    "test_x = pd.read_csv('input/test_x.csv', index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 3072)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "# from keras.utils import np_utils\n",
    "import gc \n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "from keras.utils import np_utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "INIT_LR = 1e-3\n",
    "IMAGE_DIMS = (32 , 32 , 3)\n",
    "BATCH_SIZE = 200\n",
    "SIZE_DF = df.map.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappping_type = {'Bird': 0, 'Airplane': 1}\n",
    "train_y_bin = train_y.replace({\"target\": mappping_type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = [[np.array(x)] for x in train_x.values]\n",
    "d = {'map': d1, 'target': train_y_bin.target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7200,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>map</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[4, 20, 18, 4, 16, 15, 2, 11, 9, 2, 6, 5, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[109, 155, 233, 109, 155, 231, 110, 156, 232,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[156, 172, 195, 158, 174, 197, 158, 174, 197,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[115, 108, 52, 97, 100, 79, 86, 107, 98, 79, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[167, 205, 221, 160, 198, 213, 161, 198, 214,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 map  target\n",
       "0  [[4, 20, 18, 4, 16, 15, 2, 11, 9, 2, 6, 5, 1, ...       0\n",
       "1  [[109, 155, 233, 109, 155, 231, 110, 156, 232,...       1\n",
       "2  [[156, 172, 195, 158, 174, 197, 158, 174, 197,...       1\n",
       "3  [[115, 108, 52, 97, 100, 79, 86, 107, 98, 79, ...       1\n",
       "4  [[167, 205, 221, 160, 198, 213, 161, 198, 214,...       1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760,)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_gen_cat(in_df, batch_size=BATCH_SIZE):\n",
    "    all_batches = in_df.sample(frac=1)\n",
    "    out_map = []\n",
    "    out_class = []\n",
    "    size = in_df.shape[0]\n",
    "    indexes = np.random.randint(0, size, size)\n",
    "    while True:\n",
    "        for index in indexes:\n",
    "            out_map += [in_df.map.values[index][0]/255.]\n",
    "            out_class += [in_df.target.values[index]]\n",
    "            if len(out_map) >= batch_size:\n",
    "                out_map = np.array(out_map)\n",
    "                out_map = out_map.reshape(out_map.shape[0], IMAGE_DIMS[0], IMAGE_DIMS[1], IMAGE_DIMS[2])\n",
    "                yield np.stack(out_map, 0), np.array(np_utils.to_categorical(out_class, num_classes=2))\n",
    "                out_map = []\n",
    "                out_class = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 1440)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2)\n",
    "train_df.shape[0], valid_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "dg_args = dict(featurewise_center = False, \n",
    "               samplewise_center = False,\n",
    "               rotation_range = 15, \n",
    "               width_shift_range = 0.1, \n",
    "               height_shift_range = 0.1, \n",
    "               shear_range = 0.01,\n",
    "               zoom_range = [0.9, 1.25])\n",
    "\n",
    "# dg_args = dict(featurewise_center = False, \n",
    "#                samplewise_center = False,\n",
    "#                rotation_range = 5, \n",
    "#                width_shift_range = 0.1, \n",
    "#                height_shift_range = 0.1)\n",
    "\n",
    "\n",
    "image_gen = ImageDataGenerator(**dg_args)\n",
    "def create_aug_gen(in_gen, seed=None):\n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    for in_x, in_y in in_gen:\n",
    "        seed = np.random.choice(range(9999))\n",
    "        g_x = image_gen.flow(255*in_x, \n",
    "                             batch_size=in_x.shape[0])\n",
    "\n",
    "        yield next(g_x)/255., in_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (20, 32, 32, 3)\n",
      "y (20, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen = make_image_gen_cat(train_df)\n",
    "train_x, train_y = next(train_gen)\n",
    "print('x', train_x.shape)\n",
    "print('y', train_y.shape)\n",
    "cur_gen = create_aug_gen(train_gen)\n",
    "t_x, t_y = next(cur_gen)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 32, 32, 3) (20, 2)\n",
      "[0. 1.]\n",
      "Wall time: 15.9 ms\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "valid_x, valid_y = next(make_image_gen_cat(train_df))\n",
    "print(valid_x.shape, valid_y.shape)\n",
    "\n",
    "n = 16\n",
    "plt.imshow(valid_x[n,:,:])\n",
    "print(valid_y[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallerVGGNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes, finalAct=\"softmax\"):\n",
    "        # initialize the model along with the input shape to be\n",
    "        # \"channels last\" and the channels dimension itself\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "\n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        # and channels dimension\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "\n",
    "        # CONV => RELU => POOL\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\", \n",
    "                         input_shape=(IMAGE_DIMS[0], IMAGE_DIMS[1], IMAGE_DIMS[2])))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(48, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(48, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(80, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(80, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(80, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(80, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(80, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "#                 # (CONV => RELU) * 2 => POOL\n",
    "#         model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "#         model.add(Dropout(0.4))\n",
    "\n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # use a *softmax* activation for single-label classification\n",
    "        # and *sigmoid* activation for multi-label classification\n",
    "        model.add(Dense(classes))\n",
    "        \n",
    "        model.add(Activation(finalAct))\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
    "                            depth=IMAGE_DIMS[2], classes=2, \n",
    "                            finalAct=\"sigmoid\")\n",
    " \n",
    "# initialize the optimizer\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_72 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 32, 32, 48)        13872     \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 32, 32, 48)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 32, 32, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 32, 32, 48)        20784     \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 32, 32, 48)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 32, 32, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 16, 16, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 16, 16, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 16, 16, 80)        34640     \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 16, 16, 80)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 16, 16, 80)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 16, 16, 80)        57680     \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 16, 16, 80)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 16, 16, 80)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 16, 16, 80)        57680     \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16, 16, 80)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 16, 16, 80)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 16, 16, 80)        57680     \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16, 16, 80)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 16, 16, 80)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 16, 16, 80)        57680     \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 16, 16, 80)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 16, 16, 80)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 8, 8, 80)          0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 8, 8, 80)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 500)               2560500   \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 1002      \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,885,278\n",
      "Trainable params: 2,883,094\n",
      "Non-trainable params: 2,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, dice_coef, acc, _ = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\n - Testing loss: {:.4f} - dice_coef: {:.4f} - acc: {:.4f}\\n'.format(loss, dice_coef, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2575"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "weight_path=\"C:\\\\Users\\\\user\\\\Python_Code\\\\Kaggle\\\\Plane&Bird\\\\strong_weights_2.h5\"\n",
    "# weight_path = ''\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_acc', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only=True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_acc', factor=0.33,\n",
    "                                   patience=3, verbose=1, mode='max',\n",
    "                                   min_delta=0.0001, cooldown=0, min_lr=1e-6)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", verbose=2, \n",
    "                      patience=10)\n",
    "\n",
    "\n",
    "\n",
    "callbacks_list = [checkpoint, reduceLROnPlat, early]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "\n",
    "model.compile(optimizer=Adam(1e-3, decay=1e-6), \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", \n",
    "                      metrics.categorical_accuracy])\n",
    "\n",
    "def reset_weights(model):\n",
    "    session = K.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)\n",
    "            \n",
    "reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6078 - acc: 0.7340 - categorical_accuracy: 0.7340 - val_loss: 0.9152 - val_acc: 0.6780 - val_categorical_accuracy: 0.6780\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.53500 to 0.67800, saving model to C:\\Users\\user\\Python_Code\\Kaggle\\Plane&Bird\\strong_weights_2.h5\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.4588 - acc: 0.8030 - categorical_accuracy: 0.8030 - val_loss: 0.4681 - val_acc: 0.8100 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.67800 to 0.81000, saving model to C:\\Users\\user\\Python_Code\\Kaggle\\Plane&Bird\\strong_weights_2.h5\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.4401 - acc: 0.8165 - categorical_accuracy: 0.8165 - val_loss: 0.5979 - val_acc: 0.8030 - val_categorical_accuracy: 0.8030\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.81000\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.4266 - acc: 0.8240 - categorical_accuracy: 0.8240 - val_loss: 0.3926 - val_acc: 0.8445 - val_categorical_accuracy: 0.8445\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.81000 to 0.84450, saving model to C:\\Users\\user\\Python_Code\\Kaggle\\Plane&Bird\\strong_weights_2.h5\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.3989 - acc: 0.8295 - categorical_accuracy: 0.8295 - val_loss: 0.8186 - val_acc: 0.7485 - val_categorical_accuracy: 0.7485\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.84450\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.3723 - acc: 0.8365 - categorical_accuracy: 0.8365 - val_loss: 0.4148 - val_acc: 0.8260 - val_categorical_accuracy: 0.8260\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.84450\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 0.3590 - acc: 0.8565 - categorical_accuracy: 0.8565 - val_loss: 0.4806 - val_acc: 0.7860 - val_categorical_accuracy: 0.7860\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.84450\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00033000001567415896.\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 0.3101 - acc: 0.8780 - categorical_accuracy: 0.8780 - val_loss: 0.4014 - val_acc: 0.8475 - val_categorical_accuracy: 0.8475\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.84450 to 0.84750, saving model to C:\\Users\\user\\Python_Code\\Kaggle\\Plane&Bird\\strong_weights_2.h5\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.3290 - acc: 0.8625 - categorical_accuracy: 0.8625 - val_loss: 0.3511 - val_acc: 0.8445 - val_categorical_accuracy: 0.8445\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.84750\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.2661 - acc: 0.8945 - categorical_accuracy: 0.8945 - val_loss: 0.3899 - val_acc: 0.8470 - val_categorical_accuracy: 0.8470\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.84750\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 0.2292 - acc: 0.9075 - categorical_accuracy: 0.9075 - val_loss: 0.3764 - val_acc: 0.8455 - val_categorical_accuracy: 0.8455\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.84750\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010890000325161964.\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.2567 - acc: 0.8845 - categorical_accuracy: 0.8845 - val_loss: 0.3113 - val_acc: 0.8575 - val_categorical_accuracy: 0.8575\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.84750 to 0.85750, saving model to C:\\Users\\user\\Python_Code\\Kaggle\\Plane&Bird\\strong_weights_2.h5\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.2055 - acc: 0.9140 - categorical_accuracy: 0.9140 - val_loss: 0.3729 - val_acc: 0.8505 - val_categorical_accuracy: 0.8505\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.85750\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 0.1686 - acc: 0.9325 - categorical_accuracy: 0.9325 - val_loss: 0.3471 - val_acc: 0.8620 - val_categorical_accuracy: 0.8620\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.85750 to 0.86200, saving model to C:\\Users\\user\\Python_Code\\Kaggle\\Plane&Bird\\strong_weights_2.h5\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.2100 - acc: 0.9035 - categorical_accuracy: 0.9035 - val_loss: 0.3254 - val_acc: 0.8555 - val_categorical_accuracy: 0.8555\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.86200\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.1721 - acc: 0.9250 - categorical_accuracy: 0.9250 - val_loss: 0.3993 - val_acc: 0.8450 - val_categorical_accuracy: 0.8450\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.86200\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.1540 - acc: 0.9395 - categorical_accuracy: 0.9395 - val_loss: 0.3262 - val_acc: 0.8755 - val_categorical_accuracy: 0.8755\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.86200 to 0.87550, saving model to C:\\Users\\user\\Python_Code\\Kaggle\\Plane&Bird\\strong_weights_2.h5\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.1765 - acc: 0.9225 - categorical_accuracy: 0.9225 - val_loss: 0.2960 - val_acc: 0.8840 - val_categorical_accuracy: 0.8840\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.87550 to 0.88400, saving model to C:\\Users\\user\\Python_Code\\Kaggle\\Plane&Bird\\strong_weights_2.h5\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.1367 - acc: 0.9385 - categorical_accuracy: 0.9385 - val_loss: 0.3240 - val_acc: 0.8660 - val_categorical_accuracy: 0.8660\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.88400\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.1509 - acc: 0.9360 - categorical_accuracy: 0.9360 - val_loss: 0.3786 - val_acc: 0.8545 - val_categorical_accuracy: 0.8545\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.88400\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.1672 - acc: 0.9235 - categorical_accuracy: 0.9235 - val_loss: 0.3348 - val_acc: 0.8680 - val_categorical_accuracy: 0.8680\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.88400\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.5936999920522795e-05.\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.1147 - acc: 0.9545 - categorical_accuracy: 0.9545 - val_loss: 0.3487 - val_acc: 0.8750 - val_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.88400\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 0.1119 - acc: 0.9520 - categorical_accuracy: 0.9520 - val_loss: 0.3552 - val_acc: 0.8750 - val_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.88400\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.1143 - acc: 0.9500 - categorical_accuracy: 0.9500 - val_loss: 0.3528 - val_acc: 0.8710 - val_categorical_accuracy: 0.8710\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.88400\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.185920958960196e-05.\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0949 - acc: 0.9650 - categorical_accuracy: 0.9650 - val_loss: 0.3413 - val_acc: 0.8735 - val_categorical_accuracy: 0.8735\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.88400\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.0961 - acc: 0.9540 - categorical_accuracy: 0.9540 - val_loss: 0.3461 - val_acc: 0.8745 - val_categorical_accuracy: 0.8745\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.88400\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.0924 - acc: 0.9600 - categorical_accuracy: 0.9600 - val_loss: 0.4005 - val_acc: 0.8680 - val_categorical_accuracy: 0.8680\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.88400\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.913539212589967e-06.\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0825 - acc: 0.9705 - categorical_accuracy: 0.9705 - val_loss: 0.3452 - val_acc: 0.8870 - val_categorical_accuracy: 0.8870\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.88400 to 0.88700, saving model to C:\\Users\\user\\Python_Code\\Kaggle\\Plane&Bird\\strong_weights_2.h5\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0898 - acc: 0.9625 - categorical_accuracy: 0.9625 - val_loss: 0.3892 - val_acc: 0.8725 - val_categorical_accuracy: 0.8725\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.88700\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.0836 - acc: 0.9630 - categorical_accuracy: 0.9630 - val_loss: 0.3568 - val_acc: 0.8815 - val_categorical_accuracy: 0.8815\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.88700\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0854 - acc: 0.9650 - categorical_accuracy: 0.9650 - val_loss: 0.3527 - val_acc: 0.8730 - val_categorical_accuracy: 0.8730\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.88700\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.2914679791720119e-06.\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.0918 - acc: 0.9640 - categorical_accuracy: 0.9640 - val_loss: 0.3973 - val_acc: 0.8620 - val_categorical_accuracy: 0.8620\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.88700\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0781 - acc: 0.9660 - categorical_accuracy: 0.9660 - val_loss: 0.3584 - val_acc: 0.8740 - val_categorical_accuracy: 0.8740\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.88700\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.0740 - acc: 0.9685 - categorical_accuracy: 0.9685 - val_loss: 0.3808 - val_acc: 0.8645 - val_categorical_accuracy: 0.8645\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.88700\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0909 - acc: 0.9615 - categorical_accuracy: 0.9615 - val_loss: 0.3728 - val_acc: 0.8690 - val_categorical_accuracy: 0.8690\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.88700\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0802 - acc: 0.9690 - categorical_accuracy: 0.9690 - val_loss: 0.3565 - val_acc: 0.8830 - val_categorical_accuracy: 0.8830\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.88700\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0795 - acc: 0.9665 - categorical_accuracy: 0.9665 - val_loss: 0.3898 - val_acc: 0.8645 - val_categorical_accuracy: 0.8645\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.88700\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.0895 - acc: 0.9610 - categorical_accuracy: 0.9610 - val_loss: 0.3728 - val_acc: 0.8720 - val_categorical_accuracy: 0.8720\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.88700\n",
      "Epoch 00038: early stopping\n"
     ]
    }
   ],
   "source": [
    "gen_train_cat = make_image_gen_cat(train_df)\n",
    "gen_valid_cat = make_image_gen_cat(valid_df)\n",
    "\n",
    "aug_gen_cat = create_aug_gen(make_image_gen_cat(train_df))\n",
    "\n",
    "\n",
    "net = model.fit_generator(gen_train_cat,\n",
    "                          steps_per_epoch = 100,\n",
    "                          epochs = 100,\n",
    "                          validation_data = gen_valid_cat,\n",
    "                          validation_steps = 100,\n",
    "                          callbacks = callbacks_list,\n",
    "                          workers=1, \n",
    "                          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.6590 - acc: 0.5080 - categorical_accuracy: 0.5080 - val_loss: 2.3789 - val_acc: 0.5175 - val_categorical_accuracy: 0.5175\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.88700\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.5767 - acc: 0.5075 - categorical_accuracy: 0.5075 - val_loss: 2.3424 - val_acc: 0.5175 - val_categorical_accuracy: 0.5175\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.88700\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.3972 - acc: 0.5240 - categorical_accuracy: 0.5240 - val_loss: 2.2283 - val_acc: 0.5090 - val_categorical_accuracy: 0.5090\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.88700\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.3265 - acc: 0.5110 - categorical_accuracy: 0.5110 - val_loss: 2.0741 - val_acc: 0.5190 - val_categorical_accuracy: 0.5190\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.88700\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.2253 - acc: 0.5225 - categorical_accuracy: 0.5225 - val_loss: 1.9797 - val_acc: 0.5290 - val_categorical_accuracy: 0.5290\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.88700\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.3300 - acc: 0.4905 - categorical_accuracy: 0.4905 - val_loss: 1.9842 - val_acc: 0.5010 - val_categorical_accuracy: 0.5010\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.88700\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 2.1634 - acc: 0.4995 - categorical_accuracy: 0.4995 - val_loss: 1.8712 - val_acc: 0.5270 - val_categorical_accuracy: 0.5270\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.88700\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.0270 - acc: 0.4895 - categorical_accuracy: 0.4895 - val_loss: 1.8042 - val_acc: 0.5255 - val_categorical_accuracy: 0.5255\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.88700\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.0917 - acc: 0.4690 - categorical_accuracy: 0.4690 - val_loss: 1.8140 - val_acc: 0.5085 - val_categorical_accuracy: 0.5085\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.88700\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 1.9846 - acc: 0.4910 - categorical_accuracy: 0.4910 - val_loss: 1.7517 - val_acc: 0.5170 - val_categorical_accuracy: 0.5170\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.88700\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 1.7276 - acc: 0.5360 - categorical_accuracy: 0.5360 - val_loss: 1.6884 - val_acc: 0.5220 - val_categorical_accuracy: 0.5220\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.88700\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 1.7791 - acc: 0.5085 - categorical_accuracy: 0.5085 - val_loss: 1.6437 - val_acc: 0.5065 - val_categorical_accuracy: 0.5065\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.88700\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 1.6558 - acc: 0.5220 - categorical_accuracy: 0.5220 - val_loss: 1.5893 - val_acc: 0.5325 - val_categorical_accuracy: 0.5325\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.88700\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 1.7146 - acc: 0.5010 - categorical_accuracy: 0.5010 - val_loss: 1.5936 - val_acc: 0.5145 - val_categorical_accuracy: 0.5145\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.88700\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 1.6045 - acc: 0.5150 - categorical_accuracy: 0.5150 - val_loss: 1.5751 - val_acc: 0.5095 - val_categorical_accuracy: 0.5095\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.88700\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 1.6982 - acc: 0.4760 - categorical_accuracy: 0.4760 - val_loss: 1.5859 - val_acc: 0.5210 - val_categorical_accuracy: 0.5210\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.88700\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 1.6234 - acc: 0.5320 - categorical_accuracy: 0.5320 - val_loss: 1.5184 - val_acc: 0.5090 - val_categorical_accuracy: 0.5090\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.88700\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 1.6625 - acc: 0.4785 - categorical_accuracy: 0.4785 - val_loss: 1.4750 - val_acc: 0.4995 - val_categorical_accuracy: 0.4995\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.88700\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 1.5983 - acc: 0.4965 - categorical_accuracy: 0.4965 - val_loss: 1.5908 - val_acc: 0.4935 - val_categorical_accuracy: 0.4935\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.88700\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 1.6586 - acc: 0.4845 - categorical_accuracy: 0.4845 - val_loss: 1.4538 - val_acc: 0.5055 - val_categorical_accuracy: 0.5055\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.88700\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 1.5094 - acc: 0.5125 - categorical_accuracy: 0.5125 - val_loss: 1.4874 - val_acc: 0.5055 - val_categorical_accuracy: 0.5055\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.88700\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 1.5184 - acc: 0.5100 - categorical_accuracy: 0.5100 - val_loss: 1.4679 - val_acc: 0.4990 - val_categorical_accuracy: 0.4990\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.88700\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 1.5654 - acc: 0.5025 - categorical_accuracy: 0.5025 - val_loss: 1.4505 - val_acc: 0.5210 - val_categorical_accuracy: 0.5210\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.88700\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "gen_train_cat = create_aug_gen(make_image_gen_cat(train_df))\n",
    "gen_valid_cat = create_aug_gen(make_image_gen_cat(valid_df))\n",
    "\n",
    "aug_gen_cat = create_aug_gen(make_image_gen_cat(train_df))\n",
    "\n",
    "\n",
    "net = model.fit_generator(gen_train_cat,\n",
    "                          steps_per_epoch = 100,\n",
    "                          epochs = 100,\n",
    "                          validation_data = gen_valid_cat,\n",
    "                          validation_steps = 100,\n",
    "                          callbacks = callbacks_list,\n",
    "                          workers=1, \n",
    "                          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-237-9917dcc53360>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ggplot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plot the training loss\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = len(history.epoch)\n",
    "plt.plot(np.arange(0, N), net.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), net.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "# plot the trainingaccuracy\n",
    "plt.plot(np.arange(0, N), net.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), net.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[2*i for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_csv('input/test_x.csv', index_col=0, header=None)\n",
    "test_d1 = [[np.array(x)] for x in test_x.values]\n",
    "test_d1 = {'map': test_d1}\n",
    "test = pd.DataFrame(data=test_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_map = []\n",
    "out_class = []\n",
    "for index, row in test.iterrows():\n",
    "    out_map += [pd.Series(row).values[0][0]]\n",
    "\n",
    "out_map = np.array(out_map)\n",
    "out_map = out_map.reshape(out_map.shape[0], IMAGE_DIMS[0], IMAGE_DIMS[1], IMAGE_DIMS[2])\n",
    "out_map = np.stack(out_map, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 2)\n",
      "Wall time: 2.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test_pred = model.predict(out_map)\n",
    "\n",
    "print(y_test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 2)\n",
      "Wall time: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test_pred = model.predict(out_map)\n",
    "\n",
    "print(y_test_pred.shape)\n",
    "\n",
    "df = np.array([[i, x.argmax()] for i, x in enumerate(y_test_pred)])\n",
    "sample = pd.DataFrame(df, columns=['id', 'target'])\n",
    "\n",
    "mappping_type_inv = {0: 'Bird', 1: 'Airplane'}\n",
    "sample = sample.replace({'target': mappping_type_inv})\n",
    "\n",
    "sample.to_csv('output/submit_12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-44305efb74f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-c3ea73b844f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'output/submit_12.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "sample.to_csv('output/submit_12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
